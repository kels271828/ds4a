{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b470aa3b",
   "metadata": {},
   "source": [
    "# Convert 2012-2015 PRAMS pdf to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13782c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import camelot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Need to do something fancier with years...\n",
    "# Second page does not have years\n",
    "# If any year is missing, that whole column is not recorded in the second page\n",
    "# Can get year dict from first page\n",
    "# But also need to get missing columns from first page to translate to \n",
    "#   new year dict in second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3fdb0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_df(filename):\n",
    "    df = pd.DataFrame(data = {})\n",
    "    data = camelot.read_pdf(filename, flavor='stream', pages='all', strip_text='\\n§#¶¥*†‡◊‖±^')\n",
    "    for ii in range(2):  # assuming only two pages\n",
    "        table = data[ii]\n",
    "        data_dict = get_data_dict(table.df)\n",
    "        df = pd.concat([df, pd.DataFrame(data_dict)])\n",
    "    return df\n",
    "\n",
    "def get_data_dict(df):\n",
    "    data = {\n",
    "        'Category': [],\n",
    "        'Indicator': [],\n",
    "        'Year': [],\n",
    "        'SampleSize': [],\n",
    "        'Prevalence': [],\n",
    "        'CI': []\n",
    "    }\n",
    "    for ii in range(len(df)):\n",
    "        if is_category(ii, df):\n",
    "            category = df.iloc[ii, 0]\n",
    "        if is_year(ii, df):\n",
    "            year_dict = get_year_dict(ii, df)\n",
    "        if is_indicator(ii, df):\n",
    "            indicator = df.iloc[ii, 0][2:]\n",
    "            print(f\"row: {ii}\")\n",
    "            add_row(ii, df, data, category, indicator, year_dict)    \n",
    "    return data\n",
    "\n",
    "def add_row(ii, df, data, category, indicator, year_dict, sub_indicator=np.nan):\n",
    "    if is_indicator(ii, df):\n",
    "        for year in year_dict:\n",
    "            stats = df.iloc[ii, year_dict[year]]\n",
    "            if stats != '':  # only append years with data\n",
    "                data['Category'].append(category)\n",
    "                data['Indicator'].append(indicator)\n",
    "                data['Year'].append(year)\n",
    "                data['SampleSize'].append(df.iloc[ii, year_dict[year] - 1])\n",
    "                data['Prevalence'].append(stats.split()[0])\n",
    "                data['CI'].append(stats.split()[1])\n",
    "    else:\n",
    "        raise ValueError(f\"Row {ii} does not contain data.\")\n",
    "\n",
    "def is_category(ii, df):\n",
    "    if ii >= len(df) - 1:\n",
    "        return False\n",
    "    return df.iloc[ii, 0] != '' and df.iloc[ii, 0][0] != '-' and is_indicator(ii + 1, df)\n",
    "\n",
    "def is_year(ii, df):\n",
    "    return '2012' in df.iloc[ii, 2]\n",
    "    \n",
    "    data[0].df.iloc[2, 2]\n",
    "    return 'Overall' in df.iloc[ii, -1]\n",
    "\n",
    "def get_year_dict(ii, df):\n",
    "    if is_year(ii, df):\n",
    "        year_dict = {}\n",
    "        for jj, year in enumerate(df.iloc[ii]):\n",
    "            if ('20' in year) and ('Overall' not in year):\n",
    "                year_dict[year[:4]] = jj\n",
    "        return year_dict\n",
    "    else:\n",
    "        raise ValueError(f\"Row {ii} does not contain years.\")\n",
    "\n",
    "def is_indicator(ii, df):\n",
    "    return df.iloc[ii, 0] != '' and df.iloc[ii, 0][0] == '-'\n",
    "\n",
    "def get_name(filename):\n",
    "    name = ''\n",
    "    for word in filename.split('-')[:-2]:\n",
    "        name += word.capitalize()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "df726c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# filenames = os.listdir('../data/PRAMS/pdf/')\n",
    "# for filename in filenames:\n",
    "#     if ('2012' in filename) and ('All' not in filename):\n",
    "#         df_state = pdf_to_df('../data/PRAMS/pdf/' + filename)\n",
    "#         state_name = get_name(filename)\n",
    "#         df_state['State'] = state_name\n",
    "#         df = pd.concat([df, df_state])\n",
    "#         print(f\"State: {state_name}, Rows: {len(df_state)}\")\n",
    "# df.to_csv('../data/PRAMS/csv/PRAMS_2012_2015.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52438f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = camelot.read_pdf('../data/PRAMS/pdf/Arkansas-2012-2015.pdf', flavor='stream', pages='all', strip_text='\\n§#¶¥*†‡◊‖±^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4acf7dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2012': 2, '2013': 4, '2014': 6, '2015': 8}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_year_dict(2, data[0].df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ae9912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'877'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2014 counts\n",
    "data[0].df.iloc[6, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "79cc56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30.6 (27.8-33.6)'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2014 stats\n",
    "data[0].df.iloc[6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a930974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'870'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2014 counts\n",
    "data[1].df.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4733fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24.8 (22.0-27.7)'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2014 stats\n",
    "data[1].df.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4939c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things are shifted to the left if any preceding years are missing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
